"""Copy of Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LWWNhXME502cqolYXvQ0zVmg--jGWmSk
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv(r"C:\Users\sathi\Downloads\50_Startups.csv")

from google.colab import files
uploaded = files.upload()

# Then load the file
import pandas as pd
df = pd.read_csv('50_Startups.csv')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('./50_Startups.csv')

# lets check the first five rows of dataset
df.head()

df.info()

# summary statistics
df.describe()

df.isnull().sum()

feature_values = {col:df[col].nunique() for col in df.columns}
feature_values

categorical_features = [feature for feature in df.columns if df[feature].dtypes=='O']
categorical_features

#check count based on categorical features
sns.set(style="whitegrid")
plt.figure(figsize=(12,6))
total = float(len(df))
ax = sns.countplot(x="State", data=df)
plt.xticks(rotation=90)
plt.title("Count Plot For States", fontsize=20)
for p in ax.patches:
    percentage = '{:.1f}%'.format(100 * p.get_height()/total)
    x = p.get_x() + p.get_width() / 2.
    y = p.get_height()
    ax.annotate(percentage, (x, y),ha='center',va='bottom')
plt.show()



#Find out the relationship between categorical variable and dependent varaible
plt.figure(figsize=(12, 6))
fig = sns.boxplot(x='State', y="Profit", data=df.sort_values('Profit',ascending=False))
plt.show()

# list of numerical variables
numerical_features = [feature for feature in df.columns if ((df[feature].dtypes != 'O') & (feature not in ['Profit']))]
print('Numerical variables: ', numerical_features)

discrete_feature = [feature for feature in numerical_features if df[feature].nunique()<25]
print("Discrete Variables Count: {}".format(len(discrete_feature)))

continuous_features = [feature for feature in numerical_features if feature not in discrete_feature + ['Profit']]
continuous_features

font = {'family': 'serif',
        'color':  'darkred',
        'weight': 'normal',
        'size': 16,
        }
fig,axes = plt.subplots(1,3,figsize=(20,6),sharey=True)
fig.subplots_adjust(wspace=0.1, hspace=0.3)
fig.suptitle('Scatter Plot Of Continous Variables',fontsize = 20)
fig.subplots_adjust(top=0.95)

axes = axes.ravel()

for i,col in enumerate(continuous_features):
    #using log transformation
    sns.distplot(df[col],ax=axes[i])

fig,axes = plt.subplots(1,3,figsize=(20,6),sharey=True)
fig.subplots_adjust(wspace=0.1, hspace=0.3)
fig.suptitle('Scatter Plot Of Continuous Variables vs Profit',fontsize = 20)
fig.subplots_adjust(top=0.95)

axes = axes.ravel()

for i,col in enumerate(continuous_features):
    x = df[col]
    y = df['Profit']
    sns.scatterplot(x,ax=axes[i])

#boxplot on numerical features to find outliers
fig, ax = plt.subplots(1, 3, figsize=(20, 5))
for variable, subplot in zip(numerical_features, ax.flatten()):
    sns.boxplot(df[variable], ax=subplot)

# Checking for correlation
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(), annot=True, cmap='plasma')
plt.show()

# Install necessary libraries (if needed)
!pip install seaborn matplotlib

# Import necessary libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load your dataset (ensure you have the correct path)
df = pd.read_csv('50_Startups.csv')

# Select only numerical columns (if necessary)
numeric_df = df.select_dtypes(include=['float64', 'int64'])

# Create the heatmap for correlation
plt.figure(figsize=(10, 6))
sns.heatmap(numeric_df.corr(), annot=True, cmap='plasma')
plt.show()

# Handling Categorical Features
df_state_dummies = pd.get_dummies(df['State'],prefix='state',drop_first=True)
# concat df and state dummies
df = pd.concat([df,df_state_dummies],axis=1)

df.head()

# drop the original categorical columns
df.drop(['State'], axis=1, inplace=True)

df.shape

# Separate Dependent and Independent Variables
X = df.drop('Profit',axis=1)
y = df['Profit']

# Train-Test Split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 50)

# Hyper parameter tuning
import pandas as pd
import numpy as np
from sklearn.model_selection import RandomizedSearchCV, ShuffleSplit
from sklearn.linear_model import LinearRegression, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

def find_best_model_using_gridsearchcv(X, y):
    algos = {
        'LinearRegression': {
            'model': make_pipeline(StandardScaler(), LinearRegression()),
            'params': {
                'linearregression__fit_intercept': [True, False],
                'linearregression__copy_X': [True, False]
            }
        },
        'Lasso': {
            'model': Lasso(),
            'params': {
                'alpha': [1, 2],
                'selection': ['random', 'cyclic']
            }
        },
        'DecisionTree': {
            'model': DecisionTreeRegressor(),
            'params': {
                'criterion': ['squared_error'],  # Fewer values
                'splitter': ['best']
            }
        },
        'RandomForest': {
            'model': RandomForestRegressor(),
            'params': {
                'n_estimators': [100, 200],  # Fewer values
                'max_features': ['auto', 'sqrt'],
                'max_depth': [10, 20],  # Fewer values
                'min_samples_leaf': [1]
            }
        }
    }

    scores = []
    cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=50)  # Reduced splits for faster computation
    for algo_name, config in algos.items():
        gs = RandomizedSearchCV(config['model'], config['params'], cv=cv, n_iter=5, n_jobs=-1, return_train_score=False)  # Using RandomizedSearchCV with limited iterations
        gs.fit(X, y)
        scores.append({
            'model': algo_name,
            'best_score': gs.best_score_,
            'best_params': gs.best_params_
        })

    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])

df = pd.read_csv('./50_Startups.csv')
print(df.head())

# Preprocessing categorical 'State' column (if necessary)
# Check if 'State' column exists in df before applying get_dummies
if 'State' in df.columns:
    df = pd.get_dummies(df, columns=['State'], drop_first=True)
else:
    print("'State' column not found in the dataset")

# Define features and target
X = df.drop('Profit', axis=1)
y = df['Profit']

# Now you can proceed with the GridSearchCV function
pd.set_option('display.max_colwidth', 100)
best_models = find_best_model_using_gridsearchcv(X, y)

# Linear Regression
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

# Load your dataset
df = pd.read_csv('./50_Startups.csv')

# Preprocessing: One-hot encoding for categorical variables
if 'State' in df.columns:
    df = pd.get_dummies(df, columns=['State'], drop_first=True)

# Define features and target
X = df.drop('Profit', axis=1)
y = df['Profit']

# Split your data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a pipeline with StandardScaler and LinearRegression
lr = make_pipeline(StandardScaler(), LinearRegression(copy_X=True, fit_intercept=True))

# Fit the model on the training data
lr.fit(X_train, y_train)

# Make predictions on the test set
y_pred = lr.predict(X_test)

# Evaluate the model
score = lr.score(X_test, y_test)
print("Model Score on Test Data (R^2):", score)
print("Predicted Values on Test Data:", y_pred)
print("Actual Values on Test Data:", y_test.values)

# fit the model
lr.fit(X, y)

# checking score on test data
lr.score(X_test,y_test)

# predict on test data
y_pred= lr.predict(X_test)

def predict_profit(r_d_expenses, administration_expenses, marketing_expenses, state):
    '''
    predict profit function takes four arguments and
    converts the data into the required format for prediction.
    '''

    # Create a feature array initialized to zero
    x = np.zeros(len(X.columns))
    x[0] = r_d_expenses
    x[1] = administration_expenses
    x[2] = marketing_expenses

    # Find the state index
    state_column = 'State_' + str(state)  # Adjusting column name to match what get_dummies would produce

    if state_column in X.columns:
        state_index = np.where(X.columns == state_column)[0][0]
        x[state_index] = 1
    else:
        raise ValueError(f"State '{state}' is not recognized. Available states: {list(X.columns)}")

    # Make prediction
    return lr.predict([x])[0]

# Example prediction call
try:
    predicted_profit = predict_profit(55067.95, 102077.25, 212117.91, 'New York')
    print("Predicted Profit:", predicted_profit)
except Exception as e:
    print("Error:", e)

import pickle
# save the model for future use
pickle.dump(lr,open('startp_profit_prediction_lr_model.pkl','wb'))

#save the data columns
import json

columns = {'data_columns' : [col.lower() for col in X.columns]}

with open("columns.json","w") as f:
    f.write(json.dumps(columns))

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix
from imblearn.over_sampling import SMOTE  # For handling class imbalance
import xgboost as xgb  # XGBoost for boosting model
import seaborn as sns
import matplotlib.pyplot as plt

# Step 1: Load the dataset
data = pd.read_csv('./50_Startups.csv')

# Step 2: Preprocess Data
# Step 2: Preprocess Data
def preprocess_data(data):
    # Handle missing values for numerical columns (Impute or Drop)
    numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns
    data[numerical_columns] = data[numerical_columns].fillna(data[numerical_columns].mean())  # Fill missing values with mean only for numerical columns

    # Encode categorical variables (e.g., 'State')
    data = pd.get_dummies(data, drop_first=True)  # One-hot encoding for categorical columns

    return data

# Preprocess the data
data = preprocess_data(data)

# Proceed with the rest of the steps


# Step 3: Define Features (X) and Target (y)
X = data.drop('Profit', axis=1)  # Ensure 'Profit' is the correct column representing profitability
y = data['Profit']

# Check the distribution of the target variable y
print("Distribution of the target variable (Profit):")
print(y.value_counts())

# Check for missing values in the features
print("Missing values in features:")
print(X.isnull().sum())

# Step 4: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check for missing values in training data
print("Missing values in X_train:")
print(X_train.isnull().sum())

# Check data types of the features
print("Data types in X_train:")
print(X_train.dtypes)

# Check unique values in target variable
print("Unique values in y_train:")
print(y_train.unique())

# Step 5: Handling Class Imbalance Using SMOTE on training data only
# Check that no missing values exist in X_train before applying SMOTE
print("Checking for missing values before SMOTE...")
if X_train.isnull().values.any():
    print("X_train contains missing values!")
else:
    # Apply SMOTE only if there are no missing values
    smote = SMOTE(random_state=42)

    try:
        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
        print("SMOTE applied successfully.")
    except ValueError as e:
        print("Error while applying SMOTE:", e)

# If SMOTE was successful, proceed with scaling
if 'X_train_smote' in locals():
    # Step 6: Scaling Features
    scaler = StandardScaler()
    X_train_smote = scaler.fit_transform(X_train_smote)
    X_test = scaler.transform(X_test)

    # Step 7: Define Models for Stacking
    rf_model = RandomForestClassifier(random_state=42)
    svm_model = SVC(probability=True, random_state=42)
    mlp_model = MLPClassifier(random_state=42)

    # XGBoost model
    xgboost_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)

    # Base models for stacking
    estimators = [
        ('rf', rf_model),
        ('svm', svm_model),
        ('mlp', mlp_model)
    ]

    # Define Stacking Model with XGBoost as the final classifier
    stacking_model = StackingClassifier(
        estimators=estimators,
        final_estimator=xgboost_model,
        cv=5
    )

    # Step 8: Hyperparameter Tuning for XGBoost using GridSearchCV
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [3, 5, 7],
        'learning_rate': [0.01, 0.1, 0.2],
        'subsample': [0.8, 1.0]
    }

    grid_search = GridSearchCV(estimator=xgboost_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)
    grid_search.fit(X_train_smote, y_train_smote)

    # Best parameters from Grid Search
    best_params = grid_search.best_params_
    print(f'Best Hyperparameters for XGBoost: {best_params}')

    # Train Stacking Model with Optimized XGBoost
    stacking_model.fit(X_train_smote, y_train_smote)

    # Step 9: Model Evaluation
    y_pred = stacking_model.predict(X_test)

    # Evaluate the model performance
    accuracy = accuracy_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred)
    print(f'Accuracy: {accuracy}')
    print(f'ROC-AUC Score: {roc_auc}')
    print(classification_report(y_test, y_pred))

    # Confusion Matrix
    conf_matrix = confusion_matrix(y_test, y_pred)
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

    # Step 10: Cross-Validation to Ensure Generalization
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(stacking_model, X_train_smote, y_train_smote, cv=cv, scoring='accuracy')
    print(f'Cross-Validation Accuracy Scores: {cv_scores}')
    print(f'Mean Cross-Validation Accuracy: {np.mean(cv_scores)}')

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load the dataset
data = pd.read_csv('./50_Startups.csv')

# Preprocess Data
def preprocess_data(data):
    data.fillna(data.mean(), inplace=True)  # Fill missing values with mean
    data = pd.get_dummies(data, drop_first=True)  # One-hot encoding
    return data

data = preprocess_data(data)

# Define Features (X) and Target (y)
X = data.drop('Profit', axis=1)
y = data['Profit']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check for missing values in training data
print("Missing values in X_train:")
print(X_train.isnull().sum())

# Fit Random Forest Regressor
rf_model = RandomForestRegressor(random_state=42)
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
}

# Perform grid search
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best model
best_rf_model = grid_search.best_estimator_

# Make predictions
y_pred = best_rf_model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Absolute Error: {mae}')
print(f'Mean Squared Error: {mse}')
print(f'R² Score: {r2}')

# Feature Importance Plot
plt.figure(figsize=(12, 6))
importance = best_rf_model.feature_importances_
feature_names = X.columns
indices = np.argsort(importance)[::-1]

plt.title("Feature Importance")
plt.bar(range(X.shape[1]), importance[indices], align="center")
plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90)
plt.xlim([-1, X.shape[1]])
plt.show()

# Actual vs Predicted Scatter Plot
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')  # Line of perfect prediction
plt.xlabel('Actual Profit')
plt.ylabel('Predicted Profit')
plt.title('Actual vs Predicted Profit')
plt.grid()
plt.show()

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load the dataset
data = pd.read_csv('./50_Startups.csv')

# Preprocess Data
def preprocess_data(data):
    data.fillna(data.mean(), inplace=True)  # Fill missing values with mean

    # Handle categorical variables (State)
    if 'State' in data.columns:
        data = pd.get_dummies(data, columns=['State'], drop_first=True)  # One-hot encoding

    return data

# Preprocess the data
data = preprocess_data(data)

# Define Features (X) and Target (y)
X = data.drop('Profit', axis=1)
y = data['Profit']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check for missing values in training data
print("Missing values in X_train:")
print(X_train.isnull().sum())

# Fit Random Forest Regressor
rf_model = RandomForestRegressor(random_state=42)
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
}

# Perform grid search
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best model
best_rf_model = grid_search.best_estimator_

# Make predictions
y_pred = best_rf_model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Absolute Error: {mae}')
print(f'Mean Squared Error: {mse}')
print(f'R² Score: {r2}')

# Feature Importance Plot
plt.figure(figsize=(12, 6))
importance = best_rf_model.feature_importances_
feature_names = X.columns
indices = np.argsort(importance)[::-1]

plt.title("Feature Importance")
plt.bar(range(X.shape[1]), importance[indices], align="center")
plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90)
plt.xlim([-1, X.shape[1]])
plt.show()

# Actual vs Predicted Scatter Plot
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')  # Line of perfect prediction
plt.xlabel('Actual Profit')
plt.ylabel('Predicted Profit')
plt.title('Actual vs Predicted Profit')
plt.grid()
plt.show()

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load the dataset
data = pd.read_csv('./50_Startups.csv')

# Preprocess Data
def preprocess_data(data):
    data.fillna(data.mean(), inplace=True)  # Fill missing values with mean

    # Handle categorical variables (State)
    if 'State' in data.columns:
        data = pd.get_dummies(data, columns=['State'], drop_first=True)  # One-hot encoding

    return data

# Preprocess the data
data = preprocess_data(data)

# Define Features (X) and Target (y)
X = data.drop('Profit', axis=1)
y = data['Profit']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check for missing values in training data
print("Missing values in X_train:")
print(X_train.isnull().sum())

# Fit Random Forest Regressor
rf_model = RandomForestRegressor(random_state=42)
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
}

# Perform grid search
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best model
best_rf_model = grid_search.best_estimator_

# Make predictions
y_pred = best_rf_model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Absolute Error: {mae}')
print(f'Mean Squared Error: {mse}')
print(f'R² Score: {r2}')

# Feature Importance Plot
plt.figure(figsize=(12, 6))
importance = best_rf_model.feature_importances_
feature_names = X.columns
indices = np.argsort(importance)[::-1]

plt.title("Feature Importance")
plt.bar(range(X.shape[1]), importance[indices], align="center")
plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90)
plt.xlim([-1, X.shape[1]])
plt.show()

# Actual vs Predicted Scatter Plot
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')  # Line of perfect prediction
plt.xlabel('Actual Profit')
plt.ylabel('Predicted Profit')
plt.title('Actual vs Predicted Profit')
plt.grid()
plt.show()

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load the dataset
data = pd.read_csv('./50_Startups.csv')

# Check the structure of the dataset
print(data.head())
print(data.columns)

# Preprocess Data
def preprocess_data(data):
    # Fill missing values with mean
    data.fillna(data.mean(), inplace=True)

    # Check if the 'State' column exists and needs encoding
    if 'State' in data.columns:
        # One-hot encoding for categorical 'State' column
        data = pd.get_dummies(data, drop_first=True)

    return data

# Preprocess the data
data = preprocess_data(data)

# Define Features (X) and Target (y)
X = data.drop('Profit', axis=1)
y = data['Profit']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check for missing values in training data
print("Missing values in X_train:")
print(X_train.isnull().sum())

# Fit Random Forest Regressor
rf_model = RandomForestRegressor(random_state=42)

# Define hyperparameter grid for GridSearch
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
}

# Perform grid search
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best model from the grid search
best_rf_model = grid_search.best_estimator_

# Make predictions on the test set
y_pred = best_rf_model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Absolute Error: {mae}')
print(f'Mean Squared Error: {mse}')
print(f'R² Score: {r2}')

# Plot Feature Importance
plt.figure(figsize=(12, 6))
importance = best_rf_model.feature_importances_
feature_names = X.columns
indices = np.argsort(importance)[::-1]

plt.title("Feature Importance")
plt.bar(range(X.shape[1]), importance[indices], align="center")
plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90)
plt.xlim([-1, X.shape[1]])
plt.show()

# Actual vs Predicted Scatter Plot
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')  # Line of perfect prediction
plt.xlabel('Actual Profit')
plt.ylabel('Predicted Profit')
plt.title('Actual vs Predicted Profit')
plt.grid()
plt.show()

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load the dataset
data = pd.read_csv('./50_Startups.csv')

# Check the structure of the dataset
print(data.head())
print(data.columns)

# Preprocess Data
def preprocess_data(data):
    # Check for unique values in the 'State' column to identify issues
    if 'State' in data.columns:
        print("Unique states before cleaning:")
        print(data['State'].unique())

        # Remove any unexpected characters or whitespace
        data['State'] = data['State'].str.strip()  # Remove leading/trailing whitespace

        # Check again for unique values after cleaning
        print("Unique states after cleaning:")
        print(data['State'].unique())

        # One-hot encoding for categorical 'State' column
        data = pd.get_dummies(data, columns=['State'], drop_first=True)

    # Fill missing values with mean for numeric columns
    data.fillna(data.mean(), inplace=True)

    return data

# Preprocess the data
data = preprocess_data(data)

# Define Features (X) and Target (y)
X = data.drop('Profit', axis=1)
y = data['Profit']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check for missing values in training data
print("Missing values in X_train:")
print(X_train.isnull().sum())

# Fit Random Forest Regressor
rf_model = RandomForestRegressor(random_state=42)

# Define hyperparameter grid for GridSearch
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
}

# Perform grid search
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Get the best model from the grid search
best_rf_model = grid_search.best_estimator_

# Make predictions on the test set
y_pred = best_rf_model.predict(X_test)

# Evaluate the model
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Absolute Error: {mae}')
print(f'Mean Squared Error: {mse}')
print(f'R² Score: {r2}')

# Plot Feature Importance
plt.figure(figsize=(12, 6))
importance = best_rf_model.feature_importances_
feature_names = X.columns
indices = np.argsort(importance)[::-1]

plt.title("Feature Importance")
plt.bar(range(X.shape[1]), importance[indices], align="center")
plt.xticks(range(X.shape[1]), feature_names[indices], rotation=90)
plt.xlim([-1, X.shape[1]])
plt.show()

# Actual vs Predicted Scatter Plot
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')  # Line of perfect prediction
plt.xlabel('Actual Profit')
plt.ylabel('Predicted Profit')
plt.title('Actual vs Predicted Profit')
plt.grid()
plt.show()
